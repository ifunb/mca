{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:90%; text-align:center; border-width: 0px; display:block; margin-left:auto; margin-right:auto;\">\n",
    "<div class=\"alert alert-block alert-success\" style=\"text-align:center; color:navy;\">\n",
    "<img src=\"https://raw.githubusercontent.com/bgeneto/MCA/main/imagens/logo_unb.png\" style=\"width: 200px; opacity:0.85;\">\n",
    "<h1>Universidade de Bras√≠lia</h1>\n",
    "<h2>Instituto de F√≠sica</h2>\n",
    "<hr style=\"width:44%;border:1px solid navy;\">\n",
    "<h3>M√©todos Computacionais A (MCA)</h3> \n",
    "<h4>Prof. Bernhard Enders</h4>\n",
    "<hr style=\"width:44%;border:1px solid navy;\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **‚û≤ Aula 11 - Problemas de Valor de Contorno**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudamos anteriormente os problemas de valor inicial (PVI), onde toda a din√¢mica est√° definida pela equa√ß√£o diferencial, o valor de uma fun√ß√£o desconhecida $y$ e, eventualmente, de algumas de suas derivadas de ordem mais alta sempre em um ponto inicial, digamos $t_0$. Em particular, se a equa√ß√£o diferencial envolve $y$, $y'$ e $y''$, o problema toma a seguinte forma:\n",
    "\n",
    "\\begin{align*}\n",
    "y''(t)  &= f(t, y(t), y'(t))\\quad\\quad t > t_0, \\\\\n",
    "y(t_0)  &= \\alpha, \\\\\n",
    "y'(t_0) &= \\beta.\n",
    "\\end{align*}\n",
    "\n",
    "Por√©m, h√° situa√ß√µes em que n√£o conhecemos os valores das derivadas de $y$ no ponto inicial. Se tivermos apenas o valor de $y$ em um ponto ainda sobrar√° um grau de liberdade (para problemas de segunda ordem) e a equa√ß√£o diferencial n√£o ter√° a sua solu√ß√£o completamente determinada. Para contornar isso, uma outra possibilidade √© conhecermos o valor de $y$ em outro ponto al√©m do inicial. Por exemplo, podemos estar interessados em considerar problemas do tipo\n",
    "\n",
    "\\begin{align*}\n",
    "y''(x)  &= f(x, y(x), y'(x))\\quad\\quad a < x < b, \\\\\n",
    "y(a) &= \\alpha, \\\\\n",
    "y(b) &= \\beta.\n",
    "\\end{align*}\n",
    "\n",
    "Nesse caso conhecemos os valores que de $y$ em dois pontos, chamados de *valores de contorno*. Um exemplo √© o estudo do movimento de um proj√©til quando conhecemos apenas a for√ßa que age sobre ele e a sua posi√ß√£o e final, mas n√£o conhecemos a sua velocidade inicial. Este tipo de problema √© denominado *Problema de Valor de Contorno (PVC)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ‚û• Aproxima√ß√µes de Diferen√ßas Finitas\n",
    "---\n",
    "\n",
    "Vamos estudar inicialmente o M√©todo de Diferen√ßas Finitas (MDF) para resolver um PVC. Assim como foi feito no caso do PVI, mais uma vez vamos considerar uma discretiza√ß√£o do intervalo $a = x_0 < x_1 < x_2 < \\ldots < x_N = b$ e o nosso objetivo ser√° simplesmente encontrar aproxima√ß√µes $y_i$ do valores da (fun√ß√£o) solu√ß√£o nos pontos $x_i$. Ou seja, queremos encontrar $y_i$ tal que\n",
    "\n",
    "$$\n",
    "y_i\\approx y(x_i),\\quad\\quad i = 0, \\ldots, N,\n",
    "$$\n",
    "em que $y$ √© a solu√ß√£o do PVC.\n",
    "\n",
    "A grande dificuldade de resolver uma equa√ß√£o diferencial √© lidar com os termos que envolvem as derivadas (primeira e segunda) da fun√ß√£o desconhecida. Vamos tentar evitar isso aproximando essas derivadas por f√≥rmulas que dependem apenas dos valores de $y$. Mais uma vez a ferramenta que temos para conseguir s√£o as expans√µes de Taylor. Recapitulando, se $y$ √© $n + 1$ diferenci√°vel temos\n",
    "$$\n",
    "y(x + h) = y(x) + h y'(x) + \\frac{h^2}{2} y''(x) + \\ldots + \\frac{h^n}{n!} y^{(n)}(x) + \\frac{h^{n + 1}}{(n + 1)!} y^{(n + 1)}(\\xi),\\quad \\xi \\in (x, x + h).\n",
    "$$\n",
    "Lembrem, mais uma vez, que o ponto $\\xi$ que aparece na f√≥rmula acima n√£o √© conhecido exatamente, apenas sabemos que ele pertence ao intervalo $(x, x + h)$. \n",
    "\n",
    "Usando essa f√≥rmula podemos obter diretamente aproxima√ß√µes para a primeira derivada de $y$ que dependem apenas dos valores da fun√ß√£o $y$. De fato,\n",
    "$$\n",
    "y(x_{i + 1}) = y(x_i) + h y'(x_i) + \\frac{h^2}{2} y''(\\xi).\n",
    "$$\n",
    "Portanto,\n",
    "$$\n",
    "y'(x_i) = \\frac{y(x_{i + 1}) - y(x_i)}{h} - \\frac{h}{2} y''(\\xi).\n",
    "$$\n",
    "E, se $h$ √© pequeno, podemos escrever\n",
    "$$\n",
    "y'(x_i) \\approx \\frac{y(x_{i + 1}) - y(x_i)}{h}.\n",
    "$$\n",
    "Essa f√≥rmula √© conhecida como *diferen√ßa progressiva* e vemos que o erro nela √© proporcional a $h$. Esse tipo de aproxima√ß√£o √© dito *de ordem $h$* e usamos a nota√ß√£o $\\mathcal O(h)$.\n",
    "\n",
    "De maneira an√°loga podemos deduzir a f√≥rmula de *diferen√ßa regressiva*: \n",
    "$$\n",
    "y'(x_i) \\approx \\frac{y(x_{i}) - y(x_{i - 1})}{h}.\n",
    "$$\n",
    "De novo uma f√≥rmula com erro da ordem de $h$. \n",
    "\n",
    "Al√©m disso, podemos aproveitar as duas f√≥rmulas de Taylor usadas acima e conseguir algo ainda melhor\n",
    "\\begin{align*}\n",
    "y(x_{i + 1}) &= y(x_i) + h y'(x_i) + \\frac{h^2}{2} y''(x_i) + \\frac{h^3}{3!} y'''(\\xi^+),\\quad \\xi^+ \\in (x_i, x_{i + 1}) \\\\\n",
    "y(x_{i - 1}) &= y(x_i) - h y'(x_i) + \\frac{h^2}{2} y''(x_i) - \\frac{h^3}{3!} y'''(\\xi^-),\\quad \\xi^- \\in (x_{i - 1}, x_i).\n",
    "\\end{align*}\n",
    "De forma an√°loga ao que foi feito no m√©todo do ponto m√©dio na se√ß√£o anterior, ao subtrairmos essas duas f√≥rmulas obtemos\n",
    "$$\n",
    "y(x_{i + 1}) - y(x_{i -1}) = 2hy' (x_i) + \\mathcal O(h^3).\n",
    "$$\n",
    "De onde conclu√≠mos que\n",
    "$$\n",
    "y' (x_ i) = \\frac{y(x_{i + 1}) - y(x_{i -1})}{2h} + \\mathcal O(h^2).\n",
    "$$\n",
    "Essa √© uma aproxima√ß√£o para $y'$ que parece melhor do que as duas aproxima√ß√µes anteriores, pois o seu erro √© proporcional a $h^2$, um valor bem menor que $h$ para $h$ pequeno. Essa f√≥rmula √© conhecida como *diferen√ßa centrada* e geralmente √© mais interessante do que as diferen√ßas progressiva e regressiva.\n",
    "\n",
    "Agora, para podermos atacar o PVC como descrito acima, que envolve tamb√©m as derivadas segundas de $y$, precisamos de alguma aproxima√ß√£o para essa derivada. De novo, partimos das expans√µes de Taylor de $x_{i - 1}$ e $x_{i + 1}$ em torno de $x_i$.\n",
    "\\begin{align*}\n",
    "y(x_{i + 1}) &= y(x_i) + h y'(x_i) + \\frac{h^2}{2} y''(x_i) + \\frac{h^3}{3!} y'''(\\xi) + \\frac{h^4}{4!} y(\\xi^+),\\quad \\xi^+ \\in (x_i, x_{i + 1}) \\\\\n",
    "y(x_{i - 1}) &= y(x_i) - h y'(x_i) + \\frac{h^2}{2} y''(x_i) - \\frac{h^3}{3!} y'''(\\xi) + \\frac{h^4}{4!} y(\\xi^-), \\quad \\xi^- \\in (x_{i - 1}, x_i).\n",
    "\\end{align*}\n",
    "S√≥ que agora ao inv√©s de subtrair vamos somar as express√µes para obter\n",
    "$$\n",
    "y(x_{i + 1}) + y(x_{i - 1}) = 2y(x_i) + h^2 y''(x_i) + \\mathcal O(h^4).\n",
    "$$\n",
    "Isolando o $y''(x_i)$ que √© o que desejamos aproximar obtemos\n",
    "$$\n",
    "y''(x_i) = \\frac{y(x_{i + 1}) - 2y(x_ i) + y(x_{i - 1})}{h^2} + \\mathcal O(h^2).\n",
    "$$\n",
    "Isso quer dizer que a aproxima√ß√£o para a derivada\n",
    "$$\n",
    "y''(x_i) \\approx \\frac{y(x_{i + 1}) - 2y(x_ i) + y(x_{i - 1})}{h^2},\n",
    "$$\n",
    "tamb√©m √© de ordem de $h^2$, assim como a diferen√ßa centrada para aproximar $y'$. Essa aproxima√ß√£o √© conhecida tamb√©m como *diferen√ßa centrada*, mas agora para aproximar a segunda derivada.\n",
    "\n",
    "Vejamos como colocar isso em pr√°tica para resolver um PVC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©todo de diferen√ßas finitas para problemas lineares\n",
    "\n",
    "Vamos come√ßar pensando como resolver um problema de valores de contorno linear. Nesse caso consideramos que a fun√ß√£o $f$ depende de forma linear de $y$ e $y'$. Para ser mais preciso, vamos considerar que \n",
    "$$\n",
    "f(x, y, y') = -p(x)y' - q(x)y + r(x),\n",
    "$$\n",
    "para fun√ß√µes $p,\\ q,\\ r$ que dependem apenas de $x$. Assim o PVC fica\n",
    "$$\n",
    "y'' + p(x)y' + q(x)y = r(x),\\quad\\quad y(a) = \\alpha,\\quad y(b) = \\beta.\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h3>üìù EXEMPLO</h3>\n",
    "</div>\n",
    "\n",
    "Considere a seguinte equa√ß√£o diferencial e suas condi√ß√µes de contorno:\n",
    "\n",
    "$$\n",
    "y'' - 5xy' + x^2y = e^x,\\quad\\quad y(0) = 3,\\quad y(1) = 0.\n",
    "$$\n",
    "Nesse caso identificamos as fun√ß√µes $p(x) = -5x$, $q(x) = x^2$ e $r(x) = e^x$. \n",
    "\n",
    "\n",
    "O m√©todo de diferen√ßas finitas consiste em usar a equa√ß√£o diferencial e aproxima√ß√µes de derivadas calculadas anteriormente para definir equa√ß√µes que determinam as aproxima√ß√µes $y_i \\approx y(x_i)$. Por exemplo, se considerarmos o exemplo anterior e os pontos $0 = x_0 < x_1 = 1/4 < x_2 = 1/2 < x_3 = 3/4 < x_4 = 1$ podemos escrever as condi√ß√µes dadas pela equa√ß√£o diferencial como \n",
    "\\begin{align*}\n",
    "&y''(x_i) - 5 x_i y'(x_i) + x_i^2y(x_i) = e^{x_i},\\quad\\quad i = 1,\\ldots,3, \\\\\n",
    "&y(x_0) = 3, \\\\\n",
    "&y(x_4) = 0,\n",
    "\\end{align*}\n",
    "Agora substituindo os valores exatos $y(t_i)$ por suas aproxima√ß√µes $y_i$, as condi√ß√µes de contorno e as aproxima√ß√µes de derivadas centradas teremos\n",
    "\\begin{align*}\n",
    "&\\frac{y_{i + 1} - 2y_i + y_{i - 1}}{h^2} - 5 x_i \\frac{y_{i + 1} - y_{i -1}}{2h}  + x_i^2 y_i = e^{x^i}, \\quad\\quad i = 1,\\ldots,3, \\\\\n",
    "&y_0 = 3, \\\\\n",
    "&y_4 = 0.\n",
    "\\end{align*}\n",
    "Organizando as equa√ß√µes acima multiplicadas por $h^2$ obtemos\n",
    "\\begin{align*}\n",
    "&(1 + (h/2) 5x_i)y_{i - 1} + (-2 + h ^2 x_i^2)y_i + (1 - (h/2) 5x_i)y_{i + 1} = h^2 e^{x_i},\\quad\\quad i = 1,\\ldots,3, \\\\\n",
    "&y_0 = 3, \\\\\n",
    "&y_4 = 0.\n",
    "\\end{align*}\n",
    "Como os valores de $h$ e $x_i, i = 0,\\ldots,4$, s√£o conhecidos o que temos acima um **sistema de equa√ß√µes lineares** nas vari√°veis $y_1, y_2, y_3$. Recorde que $y_0$ e $y_4$ j√° t√™m os seus valores definidos. Ou seja, chegamos a um sistema simples $3 \\times 3$.\n",
    "\n",
    "Note que aqui n√£o √© poss√≠vel calcular $y_1$ somente a partir de $y_0$ como feito em problemas de valor inicial. Isso ocorre porque o valor em $y_1$ depende tanto da condi√ß√£o em $a = x_0$ quando da condi√ß√£o no outro extremo $b = x_4$. Todas as aproxima√ß√µes de $y$ que s√£o desconhecidas devem ser calculadas de uma √∫nica vez resolvendo o sistema de equa√ß√µes lineares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F√≥rmula geral para problemas lineares\n",
    "\n",
    "Deve ser natural imaginar que podemos escrever uma f√≥rmula geral, que pode ent√£o ser implementada como um programa de computador, para a aplica√ß√£o do m√©todo de diferen√ßas finitas no caso linear geral. Vejamos como fazer isso. Vamos iniciar revisitando a f√≥rmula do caso geral.\n",
    "\n",
    "$$\n",
    "y'' + p(x)y' + q(x)y = r(x),\\quad\\quad y(a) = \\alpha,\\quad y(b) = \\beta.\n",
    "$$\n",
    "\n",
    "A ideia do m√©todo de diferen√ßas finitas √© dividir o intervalo de solu√ß√£o em subintervalos usando um passo fixo $h$ de modo que $a = x_0 < x_1 < \\ldots < x_n = b$ e assim $x_{i + 1} = x_{i} + h$. A partir da√≠ devemos re-escrever a equa√ß√£o diferencial nos pontos da malha, isto √©:\n",
    "\n",
    "$$\n",
    "y''(x_i) + p(x_i)y'(x_i) + q(x_i)y(x_i) = r(x_i),\\quad i = 1, 2, \\ldots, n - 1.\n",
    "$$\n",
    "\n",
    "Por fim, devemos substituir as derivadas de $y$ pelas aproxima√ß√µes baseadas em diferen√ßas. Tamb√©m √© natural usar a melhor aproxima√ß√£o que temos. Ou seja, no caso das derivadas primeiras devemos usar diferen√ßas centradas. Ficamos com\n",
    "\n",
    "\\begin{gather}\n",
    "\\frac{y_{i + 1} - 2 y_i + y_{i - 1}}{h^2} + p_i \\frac{y_{i+1} - y_{i - 1}}{2h} + q_i y_i = r_i,\\quad \n",
    "i = 1, 2, \\ldots, n - 1. \\\\\n",
    "y_0 = \\alpha, \\quad\\quad y_{n + 1} = \\beta.\n",
    "\\end{gather}\n",
    "\n",
    "Tamb√©m √© comum multiplicar as equa√ß√µes acima por $h^2$ para eliminar as fra√ß√µes. Ficamos finalmente com\n",
    "\n",
    "\\begin{gather}\n",
    "(y_{i + 1} - 2 y_i + y_{i - 1}) + p_i h \\frac{y_{i+1} - y_{i - 1}}{2} + h^2 q_i y_i = h^2 r_i,\\quad \n",
    "i = 1, 2, \\ldots, n - 1. \\\\\n",
    "y_0 = \\alpha, \\quad\\quad y_{n + 1} = \\beta.\n",
    "\\end{gather}\n",
    "\n",
    "Separando os termos que aparecem na frente das vari√°veis $y_{i - 1}, y_i, y_{i + 1}$ chegamos a\n",
    "\n",
    "\\begin{gather}\n",
    "(1 - h/2\\ p_i) y_{i - 1} + (-2 + h^2 q_i) y_i + (1 + h/2\\ p_i) y_{i + 1} = h^2 r_i,\n",
    "i = 1, 2, \\ldots, n - 1. \\\\\n",
    "y_0 = \\alpha, \\quad\\quad y_{n + 1} = \\beta.\n",
    "\\end{gather}\n",
    "\n",
    "Ou seja, um sistema de equa√ß√µes lineares.\n",
    "\n",
    "Notem que apesar do sistema acima parecer ser inicialmente de $n + 1$ equa√ß√µes e vari√°veis, duas vari√°veis, $y_0$ e $y_n$, t√™m os seus valores definidos trivialmente pelas duas √∫ltimas equa√ß√µes. Portanto resta apenas um sitema nas $n - 1$ vari√°veis $y_1, y_2, \\ldots, y_{n - 1}$.\n",
    "\n",
    "Podemos tamb√©m representar o sistema em sua forma matricial,\n",
    "\n",
    "$$\n",
    "\\mathbf{A} y = \\mathrm{\\mathbf{b}},\n",
    "$$\n",
    "com \n",
    "$$\n",
    "A = \\left( \\begin{array}{ccccc}\n",
    "b_1 & c_1 & & & \\\\\n",
    "a_2 & b_2 & c_2 & & \\\\\n",
    "& \\ddots & \\ddots & \\ddots & \\\\\n",
    "& & a_{n - 2} & b_{n - 2} & c_{n - 2} \\\\\n",
    "& & & a_{n - 1} & b_{n - 1}\n",
    "\\end{array} \\right)\n",
    "\\quad\\quad\n",
    "b = \\left( \\begin{array}{c}\n",
    "h^2 r_1 - a_1 \\alpha \\\\\n",
    "h^2 r_2 \\\\\n",
    "\\vdots \\\\\n",
    "h^2 r_{n - 2} \\\\\n",
    "h^2 r_{n - 1} - c_{n - 1} y_n\n",
    "\\end{array} \\right).\n",
    "$$\n",
    "$$\n",
    "a_i = 1 - h/2\\ p_i,\\quad\\quad b_i = -2 + h^2q_i,\\quad\\quad c_i = 1 + h/2\\ p_i,\\quad\\quad i = 1, 2, \\ldots, n - 1.\n",
    "$$\n",
    "\n",
    "Uma observa√ß√£o importante √© que a matriz do sistema √© **tridiagonal**. Ela possui apenas a diagonal principal e as primeiras diagonais superior e inferior n√£o nulas. Isso permite resolver o sistema linear muito rapidamente, uma implementa√ß√£o que leva isso em considera√ß√£o (e.g. Algoritmo de Thomas) √© capaz de resolver esse problema com grande efici√™ncia, com complexidade computacional $\\mathcal O(n)$, ao inv√©s de ordem c√∫bica que est√° usualmente associada √† fatora√ß√£o de matrizes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
